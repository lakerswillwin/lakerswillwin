<!DOCTYPE html>
<html 
	lang="CH-zh">
	<head>
		<meta charset="UTF-8" />
		<meta http-equiv="X-UA-Compatible" content="IE=edge" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0" />
		
<link rel="stylesheet" href="/css/layout.css">

		
		<title> 计算机体系结构 -  Laneのhome</title>
		<!-- <link rel="stylesheet" href="https://unpkg.com/mdui@1.0.2/dist/css/mdui.min.css" /> -->
		<!-- <script src="https://unpkg.com/mdui@1.0.2/dist/js/mdui.min.js"></script> -->
		
<link rel="stylesheet" href="/lib/mdui/mdui.min.css">

		
<script src="/lib/mdui/mdui.min.js"></script>

		<!-- lazyload -->
		
<script src="/lib/lazysizes.js"></script>

		<!-- smooth-scrolling -->
		
<script src="/lib/smooth-scrolling.js"></script>

		<!-- highlight -->
		
<link rel="stylesheet" href="/lib/highlight/atom-one-dark.min.css">

		
<script src="/lib/highlight/highlight.min.js"></script>

		<!-- 预置 kiraicon -->
		
<link rel="stylesheet" href="/lib/iconfont/iconfont.css">

		
		<link
			rel="shortcut icon"
			href="https://kira.host/assets/Pictures/Others/116359b4ccf19917.jpg"
			type="image/png"
		/>
		
<link rel="stylesheet" href="/deps/css/APlayer.min.css">

		
			
				
<link rel="stylesheet" href="/style.css">

			
		
		
<script src="/deps/js/APlayer.min.js"></script>
<script src="/deps/js/Meting.min.js"></script>

	<meta name="generator" content="Hexo 6.3.0"></head>

	<body>
		<div
			class="kira-background"
			style="background-image: url('https://s21.ax1x.com/2024/08/08/pkzljdH.jpg')"
		></div>
		<div class="kira-header">
    <a
        class="kira-drawer-button mdui-ripple"
        title="导航栏"
        onclick="document.querySelector('.kira-sidebar-modal').classList.add('show');document.querySelector('.kira-sidebar#sidebar').classList.add('show');"
    >
        <i class="kirafont icon-menu"></i>
    </a>
    <a href="/" title="Laneのhome">
        <img
			src="https://s21.ax1x.com/2024/08/08/pkzljdH.jpg"
			alt="Lane"
		/>
    </a>
</div>
		<div class="kira-body">
			<div class="kira-sidebar" id="sidebar">
	<div class="kira-avatar mdui-ripple">
		<a target="_blank" rel="noopener" href="https://s21.ax1x.com/2024/08/08/pkzljdH.jpg" title="Lane">
			<img
				src="https://s21.ax1x.com/2024/08/08/pkzljdH.jpg"
				alt="Lane"
			/>
		</a>
	</div>
	<div class="kira-count">
		<div><span>文章</span>32</div>
		<div><span>标签</span>16</div>
		<div><span>分类</span>7</div>
	</div>
	<div class="kira-list">
		
		<a
			class="kira-list-item mdui-ripple false"
			href="/index/index.html"
			title="指路楼"
		>
			<i
				class="kirafont
					
						icon-home
					"
			></i>
			<div class="kira-list-item-content">
				指路楼
			</div>
		</a>
		
		<a
			class="kira-list-item mdui-ripple false"
			href="/archive.html"
			title="文章归档"
		>
			<i
				class="kirafont
					
						icon-container
					"
			></i>
			<div class="kira-list-item-content">
				文章归档
			</div>
		</a>
		
		<a
			class="kira-list-item mdui-ripple false"
			href="/about/about.html"
			title="本人"
		>
			<i
				class="kirafont
					
						icon-user
					"
			></i>
			<div class="kira-list-item-content">
				本人
			</div>
		</a>
		
		<a
			class="kira-list-item mdui-ripple false"
			href="/friends.html"
			title="友链"
		>
			<i
				class="kirafont
					
						icon-team
					"
			></i>
			<div class="kira-list-item-content">
				友链
			</div>
		</a>
		
		<a
			class="kira-list-item mdui-ripple false"
			href="/todolist/index.html"
			title="todolist"
		>
			<i
				class="kirafont
					
						icon-unordered-list
					"
			></i>
			<div class="kira-list-item-content">
				todolist
			</div>
		</a>
		
	</div>
	<aside id="kira-sidebar">
		
			<div class="kira-widget-wrap">
	<div class="kira-widget kira-social">
		
			<a
				class="mdui-ripple"
				href="https://wx.mail.qq.com/home/index?sid=zRxMToxhT2suJFZaALhEUwAA#/list/1/1"
				target="_blank"
				mdui-tooltip="{content: 'QQ'}"
				style="color: rgb(49, 174, 255); background-color: rgba(49, 174, 255, .1);"
			>
				<i
					class="kirafont
					
						icon-QQ
					"
				></i>
			</a>
		
			<a
				class="mdui-ripple"
				href="https://space.bilibili.com/3537107830179843?spm_id_from=333.1007.0.0"
				target="_blank"
				mdui-tooltip="{content: '哔哩哔哩'}"
				style="color: rgb(231, 106, 141); background-color: rgba(231, 106, 141, .15);"
			>
				<i
					class="kirafont
					
						icon-bilibili
					"
				></i>
			</a>
		
			<a
				class="mdui-ripple"
				href="https://github.com/lakerswillwin/"
				target="_blank"
				mdui-tooltip="{content: 'GitHub'}"
				style="color: rgb(25, 23, 23); background-color: rgba(25, 23, 23, .15);"
			>
				<i
					class="kirafont
					
						icon-github
					"
				></i>
			</a>
		
			<a
				class="mdui-ripple"
				href="/null"
				target="_blank"
				mdui-tooltip="{content: 'Gitee'}"
				style="color: rgb(165, 15, 15); background-color: rgba(165, 15, 15, .15);"
			>
				<i
					class="kirafont
					
						icon-gitee
					"
				></i>
			</a>
		
	</div>
</div>

		
			
  <div class="kira-widget-wrap">
    <h3 class="kira-widget-title">分类</h3>
    <div class="kira-widget">
      <ul class="category-list">
        
        

        
          <li class="category-list-item">
            <a class="category-list-link" href="/categories/cs课程/">
              cs课程
            </a>
            <span class="category-list-count">15</span>
          </li>
        
          <li class="category-list-item">
            <a class="category-list-link" href="/categories/思政课/">
              思政课
            </a>
            <span class="category-list-count">1</span>
          </li>
        
          <li class="category-list-item">
            <a class="category-list-link" href="/categories/技术/">
              技术
            </a>
            <span class="category-list-count">8</span>
          </li>
        
          <li class="category-list-item">
            <a class="category-list-link" href="/categories/数理课程/">
              数理课程
            </a>
            <span class="category-list-count">4</span>
          </li>
        
          <li class="category-list-item">
            <a class="category-list-link" href="/categories/科研训练/">
              科研训练
            </a>
            <span class="category-list-count">1</span>
          </li>
        
          <li class="category-list-item">
            <a class="category-list-link" href="/categories/课程经验/">
              课程经验
            </a>
            <span class="category-list-count">1</span>
          </li>
        
          <li class="category-list-item">
            <a class="category-list-link" href="/categories/随笔/">
              随笔
            </a>
            <span class="category-list-count">2</span>
          </li>
        
      </ul>
    </div>
  </div>

		
			
	<div class="kira-widget-wrap">
		<div id="randomtagcloud" class="kira-widget tagcloud kira-rainbow">
			<a href="/tags/C/" style="font-size: 20px;">C</a> <a href="/tags/C/" style="font-size: 13.33px;">C++</a> <a href="/tags/ai/" style="font-size: 10px;">ai</a> <a href="/tags/c/" style="font-size: 10px;">c</a> <a href="/tags/java/" style="font-size: 10px;">java</a> <a href="/tags/latex/" style="font-size: 10px;">latex</a> <a href="/tags/math/" style="font-size: 16.67px;">math</a> <a href="/tags/nihao/" style="font-size: 10px;">nihao</a> <a href="/tags/physics/" style="font-size: 10px;">physics</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/shell/" style="font-size: 10px;">shell</a> <a href="/tags/%E5%BB%BA%E7%AB%99/" style="font-size: 10px;">建站</a> <a href="/tags/%E6%80%9D%E6%94%BF/" style="font-size: 10px;">思政</a> <a href="/tags/%E7%A1%AC%E4%BB%B6/" style="font-size: 13.33px;">硬件</a> <a href="/tags/%E7%A7%91%E7%A0%94/" style="font-size: 10px;">科研</a> <a href="/tags/%E7%BB%8F%E9%AA%8C/" style="font-size: 10px;">经验</a>
		</div>
		
	</div>


		
			
	<div class="kira-widget-wrap">
		<h3 class="kira-widget-title">
			文章归档
		</h3>
		<div class="kira-widget">
			<ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/">2025</a><span class="archive-list-count">32</span></li></ul>
		</div>
	</div>


		
	</aside>
	<div class="kira-copyright">
		&copy; 2025
		<a href="/">Lane</a>
		Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> &
		<a href="https://github.com/ch1ny/kira-hexo/" target="_blank">Kira-Hexo</a>
		<br />
		
		<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<center> 浏览量：<span id="busuanzi_value_site_pv"><i class="fa fa-spinner fa-spin"></i></span>| 访客数：<span id="busuanzi_value_site_uv"><i class="fa fa-spinner fa-spin"></i></span> </center>
	</div>
</div>
<div
	class="kira-sidebar-modal"
	id="sidebar-modal"
	onclick="(function(self) {
		self.classList.remove('show');
		document.querySelector('.kira-sidebar.show#sidebar').classList.remove('show');
	})(this)"
></div>
			<div class="kira-content">
				<div id="kira-top-header"></div>
				<div class="kira-main-content">
					
<link rel="stylesheet" href="/css/kira-image.css">


<script src="/js/kira-image.js"></script>

<div class="kira-image">
    <div class="kira-image-modal">
        <div class="kira-image-header">
            <div class="kira-image-counter"></div>
            <div class="kira-image-title"></div>
            <div class="kira-image-operation">
                <div class="kira-image-operation-button" id="kira-image-operation-button-zoom">
                    <i class="kirafont icon-zoom-in"></i>
                </div>
                <div class="kira-image-operation-button" id="kira-image-operation-button-close">
                    <i class="kirafont icon-close"></i>
                </div>
            </div>
        </div>
        <div class="kira-image-container">
            <div class="kira-image-prev-button-panel">
                <div class="kira-image-exchange-button">
                    <i class="kirafont icon-left"></i>
                </div>
            </div>
            <div class="kira-image-list">
                <div class="kira-image-prev">
                    <img />
                </div>
                <div class="kira-image-now">
                    <img />
                </div>
                <div class="kira-image-next">
                    <img />
                </div>
            </div>
            <div class="kira-image-next-button-panel">
                <div class="kira-image-exchange-button">
                    <i class="kirafont icon-right"></i>
                </div>
            </div>
        </div>
    </div>
</div>

	
<link rel="stylesheet" href="/css/kira-code-copy.css">

	
<script src="/js/kira-code-copy.js"></script>


<div class="kira-post">
	<article>
		
		<div class="kira-post-cover">
			<img
				data-src="https://s21.ax1x.com/2024/09/25/pAQbpgP.jpg"
				data-sizes="auto"
				alt="计算机体系结构"
				class="lazyload kira-post-cover-image disabled-kira-image"
			/>
			<h1>计算机体系结构</h1>
		</div>
		
		<div class="kira-post-meta kira-rainbow" style="margin:10px 0!important;">
			<a><i class="kirafont icon-calendar-fill"></i>2025年05月23日</a>
			<a><i class="kirafont icon-edit-fill"></i>7.8k 字</a>
			<a><i class="kirafont icon-time-circle-fill"></i>大概 34 分钟</a>
		</div>
		<h2><span id="导航">导航</span></h2><ul>
<li><a href="#%E5%AF%BC%E8%88%AA">导航</a></li>
<li><a href="#%E6%88%90%E7%BB%A9%E6%9E%84%E6%88%90">成绩构成</a></li>
<li><a href="#fundamentals-of-computer-design">Fundamentals of Computer Design</a><ul>
<li><a href="#introduction">Introduction</a></li>
</ul>
</li>
<li><a href="#chpater2--memory-hierarchy">chpater2–Memory Hierarchy</a><ul>
<li><a href="#introduction-of-memory">Introduction of memory</a></li>
<li><a href="#technology-trend-and-memory-hierarchy">Technology Trend and Memory Hierarchy</a><ul>
<li><a href="#memory-hierarchy">Memory Hierarchy</a><ul>
<li><a href="#inclusive-hierarchy">Inclusive Hierarchy</a></li>
<li><a href="#exclusive-hierarchy">Exclusive Hierarchy</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#four-questions-for-cache-design">four questions for cache design</a><ul>
<li><a href="#block-replacement">Block replacement</a></li>
<li><a href="#write-policy">write policy</a></li>
</ul>
</li>
<li><a href="#memory-system-performance">Memory system performance</a></li>
<li><a href="#virtual-memory">Virtual Memory</a><ul>
<li><a href="#tlb">TLB</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#chapter3--instruction-level-parallelism">chapter3–Instruction Level Parallelism</a><ul>
<li><a href="#dynamic-vs-static">dynamic vs static</a><ul>
<li><a href="#1-bit-predictor">1-bit predictor</a></li>
<li><a href="#2-bit-predictor">2-bit predictor</a></li>
<li><a href="#generalized-to-local-history">generalized to local history</a></li>
<li><a href="#correlating-predictor">correlating predictor</a></li>
<li><a href="#tournament-predictor">tournament predictor</a></li>
</ul>
</li>
<li><a href="#dynamic-sheduling-overcome-datahazard">dynamic sheduling overcome datahazard</a><ul>
<li><a href="#%E5%8A%A8%E6%80%81%E8%B0%83%E5%BA%A6%E7%9A%84%E6%80%9D%E6%83%B3">动态调度的思想</a></li>
<li><a href="#tomasulo-algorithm">Tomasulo Algorithm</a></li>
</ul>
</li>
<li><a href="#hardware-based-speculation">Hardware-Based speculation</a><ul>
<li><a href="#tomasulo-and-extended-to-handle-speculation">Tomasulo and extended to handle speculation</a></li>
</ul>
</li>
<li><a href="#exploiting-ilp-using-multiple-issue-and-static--scheduling">exploiting ILP using Multiple Issue and static  scheduling</a><ul>
<li><a href="#two-types-of-multiple-issue-processors">two types of multiple-issue processors</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#chapter4--data-level-parallelism-architecture">chapter4–Data-Level Parallelism Architecture</a><ul>
<li><a href="#41-simdvector-processor">4.1 SIMD:vector processor</a><ul>
<li><a href="#risv-v%E6%8C%87%E4%BB%A4">RISV-V指令</a></li>
<li><a href="#vector-processor">vector processor</a></li>
<li><a href="#vector-processor-example--cray-1">Vector processor example- Cray-1</a></li>
<li><a href="#memorybank">memory:bank</a></li>
<li><a href="#improve-the-performance-of-vector-process">improve the performance of vector process</a></li>
</ul>
</li>
<li><a href="#42-simd-instruction-set-extension-for-multimedia">4.2 SIMD Instruction set extension for multimedia</a></li>
<li><a href="#43-gpu">4.3 GPU</a></li>
<li><a href="#44-loop-level-parallelism">4.4 Loop-Level parallelism</a></li>
</ul>
</li>
<li><a href="#chapter-5--tlp">chapter 5–TLP</a><ul>
<li><a href="#51-multiprocessor">5.1 Multiprocessor</a><ul>
<li><a href="#introduction-1">introduction</a></li>
<li><a href="#the-catagory-of-multiprocessor">the catagory of multiprocessor</a></li>
<li><a href="#%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B">编程模型</a></li>
<li><a href="#%E5%A4%9A%E5%A4%84%E7%90%86%E5%99%A8%E5%B8%A6%E6%9D%A5%E7%9A%84%E9%97%AE%E9%A2%98">多处理器带来的问题</a></li>
</ul>
</li>
<li><a href="#52-cache-coherency">5.2 Cache Coherency</a><ul>
<li><a href="#condition-of-coherency">condition of coherency</a></li>
<li><a href="#how-to-achieve-coherency">how to achieve coherency</a></li>
<li><a href="#snooping-protocol">snooping protocol</a></li>
<li><a href="#mesi-protocol">MESI protocol</a></li>
<li><a href="#cache-coherency-distributed-shared-memory">cache coherency distributed shared memory</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2><span id="成绩构成">成绩构成</span></h2><ol>
<li>作业加实验加考试。</li>
<li>实验尽早完成（三周以后得分可能会下降，两周内完成较好），可能会有bonus。</li>
</ol>
<h2><span id="fundamentals-of-computer-design">Fundamentals of Computer Design</span></h2><h3><span id="introduction">Introduction</span></h3><ul>
<li>体系结构&#x3D;指令集+实现指令集</li>
</ul>
<h2><span id="chpater2memory-hierarchy">chpater2–Memory Hierarchy</span></h2><h3><span id="introduction-of-memory">Introduction of memory</span></h3><ul>
<li>存储器层次结构：<ul>
<li>register-&gt;cache-&gt;main memory-&gt;disk</li>
<li>离cpu越近，越小，访问速度越快</li>
</ul>
</li>
<li>两个设计关键点：<ul>
<li>时间局部性</li>
<li>空间局部性</li>
</ul>
</li>
</ul>
<h3><span id="technology-trend-and-memory-hierarchy">Technology Trend and Memory Hierarchy</span></h3><h4><span id="memory-hierarchy">Memory Hierarchy</span></h4><h5><span id="inclusive-hierarchy">Inclusive Hierarchy</span></h5><ul>
<li><p><strong>定义</strong>：上级缓存包含所有下级缓存的数据副本（如 L3 包含 L2 和 L1 的数据）。  </p>
</li>
<li><p><strong>特点</strong>：</p>
<ul>
<li><strong>数据冗余</strong>：L3 是 L1&#x2F;L2 的超集。</li>
<li><strong>一致性维护</strong>：通过监听 L3 即可判断数据是否存在（简化多核一致性协议如 MESI）。</li>
<li><strong>替换开销</strong>：L3 替换时需失效所有下级副本。</li>
</ul>
</li>
<li><p><strong>优点</strong>：</p>
<ul>
<li>简化多核一致性管理（如 Intel CPU 的 L3 缓存）。</li>
<li>快速失效（Invalidation）广播。</li>
</ul>
</li>
<li><p><strong>缺点</strong>：</p>
<ul>
<li>存储容量浪费（L3 部分空间用于备份）。</li>
</ul>
</li>
<li><p><strong>示例</strong>：</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">L1: [Data A]<br>L2: [Data A]<br>L3: [Data A, B, C]  # 必须包含 L1/L2 的所有数据<br><br></code></pre></td></tr></table></figure>

<h5><span id="exclusive-hierarchy">Exclusive Hierarchy</span></h5><ul>
<li><p>定义：上级缓存与下级缓存数据互斥（如 L2 不包含 L1 的数据）。</p>
</li>
<li><p>特点：</p>
<ul>
<li>无冗余：数据仅存在于某一级缓存。</li>
<li>高利用率：有效缓存总容量 &#x3D; L1 + L2 + L3。</li>
<li>一致性复杂：需跨多级缓存查询数据状态。</li>
</ul>
</li>
<li><p>优点：<br>最大化存储利用率（适合容量敏感场景）。</p>
</li>
<li><p>缺点：<br>一致性协议复杂（如 AMD 早期 CPU</p>
</li>
</ul>
<h3><span id="four-questions-for-cache-design">four questions for cache design</span></h3><ul>
<li>见计组笔记</li>
</ul>
<h4><span id="block-replacement">Block replacement</span></h4><ul>
<li>Lru本质上是stack replacement algorithm<ul>
<li>$B_t(n)$ represents the set of access sequences contained in a cache block of size n at time t.</li>
<li>$B_t(n)$ 是 $B_t(n+1)$的集合，也就是n增大，命中的块一定包含原来的块，也就是说命中率会上升。</li>
</ul>
</li>
<li>FIFO本质上是队列replacement algorithm</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="/./adsphoto/tixi14.png" alt="tixi14" class="lazyload"><br>解释：我感觉这张ppt的图很棒，很巧妙地使不同大小的block对于同一个sequence采用lru策略的结果放在了同一张图中。用栈来模拟LRU，栈顶是最近访问的，栈底是最久未访问的。</p>
<ul>
<li>使用门和触发器实现LRU算法<ul>
<li>让任何两个cache块之间两两结对，用一个触发器的状态来代表两个块的先后访问顺序（比如1表示A刚被访问，0表示B刚被访问）。通过门电路对触发器的状态进行逻辑组合找到LRU块。</li>
<li>假设有p个cache blocks,我们需要$\binom{p}{2}&#x3D;p * (p-1)&#x2F;2$</li>
</ul>
</li>
</ul>
<h4><span id="write-policy">write policy</span></h4><ul>
<li>对于write miss<ul>
<li>write around(no write allocate)<ul>
<li>直接在内存中写</li>
</ul>
</li>
<li>write allocate<ul>
<li>将写的块读在缓存中再写</li>
</ul>
</li>
</ul>
</li>
<li>对于write hit<ul>
<li>write through（通常和write around搭配）<ul>
<li>同时写回cache和内存</li>
</ul>
</li>
<li>write back（通常和write allocate搭配）<ul>
<li>直接在cache中写，并标记为赃块</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3><span id="memory-system-performance">Memory system performance</span></h3><h3><span id="virtual-memory">Virtual Memory</span></h3><h4><span id="tlb">TLB</span></h4><ul>
<li>本质上就是对page table做一次cache</li>
<li>而page table本质就是一个哈希表，从虚拟地址映射到物理地址</li>
</ul>
<h2><span id="chapter3instruction-level-parallelism">chapter3–Instruction Level Parallelism</span></h2><h3><span id="dynamic-vs-static">dynamic vs static</span></h3><ul>
<li>根据branch的历史数据来预测<ul>
<li>使用branch prediction buffer indexed by lower portion of branch address and 使用一位来表示taken&#x2F;untaken status(bit 1 for taken,bit 0 for untaken)</li>
</ul>
</li>
</ul>
<h4><span id="1-bit-predictor">1-bit predictor</span></h4><ul>
<li>状态机如下(利用历史数据来预测)<br><img data-fancybox="gallery" data-sizes="auto" data-src="/./jizuphoto/tixi1.png" alt="tixi1" class="lazyload"></li>
<li>在循环中使用1-bit predictor时，因为在循环中我们的选择肯定是连续相同的，则预测会非常准确。</li>
<li>然而如果是摇摆的，有可能会导致预测率相当低，远不如静态预测。</li>
</ul>
<h4><span id="2-bit-predictor">2-bit predictor</span></h4><ul>
<li>状态机如下(利用历史数据来预测)<br><img data-fancybox="gallery" data-sizes="auto" data-src="/./jizuphoto/tixi2.png" alt="tixi2" class="lazyload"></li>
<li>在摇摆情况下，预测率会更高，达到50%。</li>
<li>我们可以再进行泛化到n-bit，只是存储开销更大</li>
</ul>
<h4><span id="generalized-to-local-history">generalized to local history</span></h4><ul>
<li>前面提到的predictor其实都是在考虑前一天的预测，我们可以考虑更多的天数</li>
</ul>
<h4><span id="correlating-predictor">correlating predictor</span></h4><ul>
<li>这也叫做二级预测器，例如(1,2)预测器在预测一个分支时，利用最近一个分支的行为在一对二位分支预测器中选择。一般情况下(m,n)预测器利用最近m个分支行为在$2^m$个分支预测器中选择，其中每一个分支预测器都是n位。</li>
<li>一个(m,n)预测器的位数:$2^m<em>n</em>$由分支地址选中的预测项的数量</li>
<li>相关预测器的一个著名例子就是gshare预测器，<br><img data-fancybox="gallery" data-sizes="auto" data-src="/./adsphoto/tixi3.png" alt="tixi3" class="lazyload"></li>
</ul>
<h4><span id="tournament-predictor">tournament predictor</span></h4><ul>
<li>通常使用一个全局预测器和一个局部预测器。全局预测器使用最近的分支历史作为预测器的索引，局部预测器使用分支地址作为索引。</li>
<li>一个例子<br><img data-fancybox="gallery" data-sizes="auto" data-src="/./adsphoto/tixi4.png" alt="tixi4" class="lazyload"></li>
</ul>
<h3><span id="dynamic-sheduling-overcome-datahazard">dynamic sheduling overcome datahazard</span></h3><h4><span id="动态调度的思想">动态调度的思想</span></h4><ul>
<li>想要成功实现动态调度，我们仍然使用顺序指令发射，但我们希望一条指令能够在其数据操作数可用时立即开始执行，这样的流水线实际是乱序执行(out-of-order execution)</li>
<li>但是乱序执行可能导致WAR冒险和WAW冒险：(利用寄存器重命名可以解决)</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs cpp">fdiv.d f0,f2,f4<br>fmul.d f6,f0,f8<br>fadd.d f0,f10,f14<br></code></pre></td></tr></table></figure>

<ul>
<li><p>为了能够乱序执行，我们将简单的五级流水线ID分成两个阶段(发射、读取操作数)。</p>
</li>
<li><p>记分牌技术：</p>
<ul>
<li>结构（注意有两个乘法部件）:<br><img data-fancybox="gallery" data-sizes="auto" data-src="/./adsphoto/tixi5.png" alt="tixi5" class="lazyload"></li>
<li>例子:</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs cpp">FLD F6, <span class="hljs-number">34</span>(R2)<br>FLD F2, <span class="hljs-number">45</span>(R3)<br>FMUL.D F0, F2, F4<br>FSUB.D F8, F2, F6<br>FDIV.D F10, F0, F6<br>FADD.D F6, F8, F2 <br></code></pre></td></tr></table></figure>

<ul>
<li>instruction status<br><img data-fancybox="gallery" data-sizes="auto" data-src="/./adsphoto/tixi6.png" alt="tixi6" class="lazyload"><br>解释：指令1已经执行完成，scoreboard没有其信息。指令2没有完成WB，后面的指令要使用指令2的结果，由于数据冒险所以还没有进行读取操作数阶段。指令6是加法操作，此时<strong>存在结构冒险还没有进入发射阶段</strong>。</li>
<li>Function Component status<br><img data-fancybox="gallery" data-sizes="auto" data-src="/./adsphoto/tixi7.png" alt="tixi7" class="lazyload"><br>解释：busy代表当前这个单元是否有指令正在使用，op表示这个单元正在被哪类指令使用。Fi,Fj,Fk代表源操作数和目的操作数(Fi为目的操作数)。Qj，Qk表示表示源操作数来自哪个部件。Rj，Rk表示源操作数的状态（注意当指令正在执行时，源操作数的状态为no）。</li>
<li>在scoreboard算法中，只要我们成功过了op阶段，那么多条成功经过op阶段的指令都能并行执行，这样相比较传统的流水线也有大幅度提升。</li>
<li>总结工作要点：<ul>
<li>一条指令能否发射，一看是否有<strong>功能部件空闲可用</strong>，这个信息包含在功能状态中；二看<strong>指令要写的寄存器是否正要被别的指令写</strong>，这个信息包含在寄存器状态中，观察这个信息是为了解决 WAW 冒险。</li>
<li>一条指令能否读数，要看记分牌是否提示源寄存器不可读，如果不可读，就说明该寄存器将要被别的前序指令改写，现在的指令要等待前序指令写回，观察这个信息是为了解决 RAW 冒险。</li>
<li>一条指令能否写回，要看是否<strong>有指令需要读即将被改写的这个寄存器</strong>，具体一点来说，就是要观察标记 Yes 的Rj、Rk 对应的寄存器里是否有当前指令的目的寄存器，如果有，就说明有指令需要读取寄存器的旧值，这样一来我们就要等指令读完旧值之后再写回，观察这个信息是为了解决 WAR 冒险。</li>
<li>所以本质上以上三种数据冒险，记分牌的策略都是通过阻塞解决。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4><span id="tomasulo-algorithm">Tomasulo Algorithm</span></h4><ul>
<li><p>scoreboard并不能解决WAR和WAW这两个冒险(源于名称依赖)，只是单纯的通过阻塞解决。</p>
</li>
<li><p>理解寄存器重命名如何消除冒险</p>
<ul>
<li>代码示例</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp">fdiv.d f0,f2,f4<br>fadd.d f6,f0,f8<br>fsd f6,<span class="hljs-number">0</span>(x1)<br>fsub.d f8,f10,f14<br>fmul.d f6,f10,f8<br></code></pre></td></tr></table></figure>

<ul>
<li>我们现在考虑三个名称依赖：fadd.d使用f8时的WAR冒险，fsub.d使用f8时的WAR冒险（写后读，反依赖:两条指令共享同一个存储位置），fadd.d可能在fmul.d之后完成导致的WAW冒险（输出依赖）。</li>
<li>这三个名称依赖都可以通过寄存器重命名消除。假定存在两个临时寄存器:S和T。</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp">fdiv.d f0,f2,f4<br>fadd.d S,f0,f8<br>fsd S,<span class="hljs-number">0</span>(x1)<br>fsub.d T,f10,f14<br>fmul.d f6,f10,T<br></code></pre></td></tr></table></figure>
</li>
<li><p>保留站</p>
<ul>
<li>保留站在一个操作数可用时马上提取并缓冲它，这样就不需要从寄存器中获取操作数，这也就意味着我们的相应的数据进入保留站后<strong>数据直接拷贝</strong>而不依赖于寄存器（因为记分牌的数据还一直依赖于寄存器），这样tomasulo利用保留站就能很好地避免因为“假依赖”导致阻塞，从而提高效率。</li>
<li>发射指令时，会重命名待用操作数的寄存器说明符，改为提供寄存器重命名功能的保留站的名字。</li>
</ul>
</li>
<li><p>寄存器状态表</p>
<ul>
<li>指令在发射的时候会更新寄存器状态表，如果后序指令和前序指令的目的寄存器重合了，就用<strong>后序指令的写信息标志寄存器</strong>，表示<strong>只会把后序指令的计算结果写进寄存器</strong>，这样可以解决写后写冒险；</li>
</ul>
</li>
<li><p>使用Tomasulo算法的浮点单元基本结构<br><img data-fancybox="gallery" data-sizes="auto" data-src="/./adsphoto/tixi8.png" alt="tixi8" class="lazyload"></p>
</li>
<li><p>每一条指令经历的步骤</p>
<ul>
<li>发射阶段：从指令队列的头部获取下一条指令，如果有一个匹配的保留站为空则将这条指令发射到这个站中。如果没有空闲保留站则说明存在结构冒险，该指令停顿。如果操作数不在寄存器中，则一直跟踪将生成这些操作数的功能单元。并且在这一阶段对寄存器进行重命名。</li>
<li>执行：如果还有一个或多个操作数不可用，则在等待计算的同时观察公共数据总线。当一个操作数变为可用时，就将它放到任何一个正在等待它的保留站中。当所有操作数可用时，则在功能单元执行运算。</li>
<li>写结果：在计算出结果后，将其写到CDB上，再从CDB传送到寄存器和所有等待这一结果的保留站。存储指令一直缓存在存储缓冲区中，直到待存储值和存储地址可用为止，然后在有空闲存储器单元时立即写入结果。</li>
</ul>
</li>
<li><p>tomasulo算法的实例</p>
<ul>
<li>cycle1:<br><img data-fancybox="gallery" data-sizes="auto" data-src="/./adsphoto/tixi9.png" alt="tixi9" class="lazyload"><br>解释：在第一个周期，第一条指令发射到保留站中，并且保留站的信息更新（注意此时的Vk与记分牌不同，直接从寄存器堆中拷贝数据，A是地址偏移立即数）.寄存器结果状态也相应地更新。</li>
<li>cycle2:<br><img data-fancybox="gallery" data-sizes="auto" data-src="/./adsphoto/tixi10.png" alt="tixi10" class="lazyload"><br>解释：第二个周期，第二条指令发送到保留站，此时第一条指令刚刚执行完偏移量的计算并更新相应的A.</li>
<li>cycle3:<br><img data-fancybox="gallery" data-sizes="auto" data-src="/./adsphoto/tixi11.png" alt="tixi11" class="lazyload"><br>解释：第三个周期。第三条指令发送到保留站中。第一条指令执行完毕执行过程。第二条指令完成偏移量的计算并更新相应的A。寄存器结果状态完成相应的更新。</li>
<li>cycle4:<br><img data-fancybox="gallery" data-sizes="auto" data-src="/./adsphoto/tixi12.png" alt="tixi12" class="lazyload"><br>解释：第四个周期结束。第一条指令完成写回阶段，此时结果立马传递到CDB，然后CDB立马传递到相应的寄存器中。第二条指令执行完毕执行过程。第三条指令因为还需要第二条指令的结果所以被阻塞。第四条指令发送到保留站，此时发现第四条指令的相应的保留站中的寄存器的值已经是最新的值。</li>
<li>cycle5:<br><img data-fancybox="gallery" data-sizes="auto" data-src="/./adsphoto/tixi13.png" alt="tixi13" class="lazyload"><br>解释：第五个周期结束。第二条指令完成写回阶段。此时第三条指令和第四条指令都同时从CDB中获取到寄存器的值。并且更新这两条指令需要执行的周期数（更新在Time中，从下一周期开始执行阶段）。第五条指令因为保留站有空余于是发射到保留站中。</li>
</ul>
</li>
<li><p>常瑞老师的例子:<br><img data-fancybox="gallery" data-sizes="auto" data-src="/./adsphoto/tixi17.png" alt="tixi17" class="lazyload"><br>解释：从这个例子中我们更能看清楚Tomasulo算法的执行过程，因为我们的保留站很充足，所以我们的指令都顺利发射。同时对于load和store指令因为我们还需要计算存储位置，所以我们在第三个周期才开始执行EX阶段。在写回阶段，因为我们在CDB上传递需要时间，相当于在第四周期结束时我们的值可以传递给保留站，从下一个周期开始进行执行阶段。</p>
</li>
</ul>
<h3><span id="hardware-based-speculation">Hardware-Based speculation</span></h3><ul>
<li>因为前面的无论是scoreboard还是tomasulo算法，我们得到结果以后都直接将最终结果写入了寄存器，所以是乱序提交的。</li>
<li>但是我们从动态调度中延伸到推测，因为使用旁路值类似于执行一次推测寄存器读操作，所以我们现在的寄存器的值必须确保是正确的值，所以有了我们接下来的操作。</li>
<li>我们使用Reorder Buffer来使指令执行完成的顺序也是顺序的。结果先写到reorder buffer中，再从reorder buffer中取到结果，写入到寄存器中。我们将每条指令加上一个commit状态，对于某条指令，只有它前面的指令都commit，它才能commit。</li>
<li>Hardware-based speculation combines three key ideas:<ul>
<li>dynamic branch prediction to choose which instructions to execute</li>
<li>speculation to allow the execution of instructions before the control dependences are resolved (with the ability to undo the effects of an incorrectly speculated sequence)</li>
<li>dynamic scheduling to deal with the scheduling of different combinations of basic blocks</li>
</ul>
</li>
</ul>
<h4><span id="tomasulo-and-extended-to-handle-speculation">Tomasulo and extended to handle speculation</span></h4><ul>
<li>Issue:get instruction from FP Op Queue</li>
<li>Execution</li>
<li>Write result<ul>
<li>在与该指令相关的操作完成到该指令提交之间，ROB保存该指令的结果。</li>
<li>ROB是指令的操作数来源，就像Tomasulo算法中的保留站提供操作数一样。</li>
</ul>
</li>
<li>Commit:update register with reorder result<ul>
<li>实现speculation背后的关键思想是允许指令乱序执行，但强制它们按顺序提交，并防止任何不可撤销的操作（如更新状态或获取异常），直到指令提交。</li>
<li>重新排序缓冲区（ROB）以与Tomasulo算法中的保留站扩展寄存器集相同的方式提供额外的寄存器。</li>
</ul>
</li>
<li>在这种进化版的tomasulo，保留站也发生了变化(Qj,Qk字段以及寄存器状态字段中的保留站编号被ROB条目编号代替，以及将Dest字段加到保留站中，Dest指定的是保留站条目产生的结果在ROB中的目的地)</li>
</ul>
<p><img data-fancybox="gallery" data-sizes="auto" data-src="/./adsphoto/tixi15.png" alt="tixi15" class="lazyload"><br>ROM与保留站:<br><img data-fancybox="gallery" data-sizes="auto" data-src="/./adsphoto/tixi16.png" alt="tixi16" class="lazyload"></p>
<h3><span id="exploiting-ilp-using-multiple-issue-and-static-scheduling">exploiting ILP using Multiple Issue and static  scheduling</span></h3><h4><span id="two-types-of-multiple-issue-processors">two types of multiple-issue processors</span></h4><ul>
<li>Superscalar</li>
</ul>
<h2><span id="chapter4data-level-parallelism-architecture">chapter4–Data-Level Parallelism Architecture</span></h2><h3><span id="41-simdvector-processor">4.1 SIMD:vector processor</span></h3><ul>
<li>向量处理器是SIMD的一种实现:单独的一条指令能够对一串数据（向量）进行操作</li>
<li>两种类型:<ul>
<li>memory-memory:直接操作内存中的数据，这需要比较高的内存带宽，检查memory的依赖也较为复杂</li>
<li>vector register:先将数据加载到寄存器中再进行操作，其实就和我们以前了解到的架构一样，后面我们讨论的都默认是vector register</li>
</ul>
</li>
</ul>
<h4><span id="risv-v指令">RISV-V指令</span></h4><ul>
<li>规则:当两个操作数都是向量时，后缀使用.VV;当第二个操作数为标量时，后缀使用.VS;当第一个操作数为标量时后缀使用.SV</li>
<li>一个例子（双精度a x X加Y）</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs risv-v">vsetdcfg 4*FP64  #启用四个双精度浮点向量寄存器<br>fld f0,a<br>fld v0,x5<br>vmul v1,v0,f0<br>vld v2,x6<br>vadd v3,v1,v2<br>vst v3,x6<br>vdisable #禁用向量寄存器<br></code></pre></td></tr></table></figure>

<h4><span id="vector-processor">vector processor</span></h4><ul>
<li><p>结构：</p>
<ul>
<li>vector register</li>
<li>vector functional units</li>
<li>vector load-store units</li>
<li>scalar registers:single element for FP scalar or address</li>
</ul>
</li>
<li><p>处理方式</p>
<ul>
<li><p>Horizontal processing method</p>
<ul>
<li>vector的处理对于每一行从左到右处理，逐个计算出后再进行下一行。</li>
<li>Problems with horizontal processing:<ul>
<li>When calculating each component, RAW correlation occurs, and the pipeline efficiency is low.</li>
<li>If a static multi-functional pipeline is used, the pipeline must be switched frequently; the throughput of the pipeline is lower than that of sequential serial execution.如果是静态的多功能流水线，我们每次都要排空才能进行下一次运算，这样的效率很低。</li>
<li>The horizontal processing method is not suitable for vector processors.</li>
</ul>
</li>
</ul>
</li>
<li><p>vertical processing method(全向量并行)<br><img data-fancybox="gallery" data-sizes="auto" data-src="/./adsphoto/tixi18.jpeg" alt="tixi18" class="lazyload"></p>
<ul>
<li>如上图所示：The vector calculation is performed vertically from top to bottom in a column manner.要等加法全部都做完才能做乘法。只存在一个数据相关，执行两次功能切换。</li>
</ul>
</li>
<li><p>vertical and horizontal processing method</p>
<ul>
<li>分组计算，组内采用纵向计算，组间采用横向计算</li>
<li>核心思想：当我们的N大于硬件最大向量长度(MVL)时进行分组处理（也就是strip mining）。$N&#x3D;S * n + r$</li>
<li>伪代码:</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python">    <span class="hljs-comment"># 处理完整段</span><br><span class="hljs-keyword">for</span> s <span class="hljs-keyword">from</span> <span class="hljs-number">0</span> to S-<span class="hljs-number">1</span>:<br>    start = s × n<br>    end = start + n - <span class="hljs-number">1</span><br>    <br>    <span class="hljs-comment"># 段内垂直处理</span><br>    K[start:end] = B[start:end] + C[start:end]<br>    D[start:end] = A[start:end] × K[start:end]<br><br><span class="hljs-comment"># 处理剩余元素</span><br><span class="hljs-keyword">if</span> r &gt; <span class="hljs-number">0</span>:<br>    start = S × n<br>    end = start + r - <span class="hljs-number">1</span><br>    <br>    <span class="hljs-comment"># 剩余元素水平处理</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">from</span> start to end:<br>        K[i] = B[i] + C[i]<br>        D[i] = A[i] × K[i]<br></code></pre></td></tr></table></figure>

<ul>
<li>Data related:S+1,Function Switch:2(S+1)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4><span id="vector-processor-example-cray-1">Vector processor example- Cray-1</span></h4><p><img data-fancybox="gallery" data-sizes="auto" data-src="/./adsphoto/tixi19.jpg" alt="tixi19" class="lazyload"></p>
<ul>
<li>结构：有 8 个向量寄存器，每组向量寄存器有 64 位。有 12 条单功能流水线，可以并行工作。Each vector register Vi has a separate bus connected to 6 vector functional units。不同的功能需要的周期不同。</li>
<li>特点：<ul>
<li>Vi conflict: The source vector or result vector of each vector instruction working in parallel uses the same Vi.也就是说：当向量寄存器有依赖的时候，后续指令要在前面指令的结果出来之后再执行。这里并不是等前面的向量的每一个元素都计算完，而是等前面的向量的第一个元素计算完就开始计算第一个元素的后续指令，等第二个元素计算完就开始计算第二个元素的后续指令，以此类推。其实也是一个流水线的思想。</li>
<li>functional conflict：Each vector instruction working in parallel must use the same functional unit.如果我们的相关功能部件被占用，我们只能等待前面指令全部完成，才能开始下面的指令。</li>
</ul>
</li>
<li>instruction types of CRAY-1</li>
</ul>
<h4><span id="memorybank">memory:bank</span></h4><ul>
<li>bank(存储体)：为向量载入&#x2F;存储单元提供带宽。通常存储器系统在开始运行时存在总存储器延迟。</li>
<li>存储体基本定义:将物理存储器划分为多个独立的逻辑单元。这些单元能够：独立地进行读写操作、并行地响应多个访问请求、减少访问冲突。</li>
<li>当处理向量体系结构中的多维数组时需要引入步幅(stride)的概念:对于要收集到一个寄存器中的元素之间的距离，因为在RV64V中可寻址单位为1字节，所以步幅的单位也是字节。</li>
<li>理解了步幅的概念后我们就可以明白非单位步长可能带来的冲突：因为我们可能频繁访问同一个存储体，所以当满足以下公式时就可能造成冲突:$\frac{number of bank}{least common multiple of bank and stride} \lq bank busy time$</li>
</ul>
<h4><span id="improve-the-performance-of-vector-process">improve the performance of vector process</span></h4><ul>
<li>optimzation 1:vector chaining<ul>
<li>流水线中forwarding的思想迁移到了向量计算中，我们在得到结果后便可以将数据通过chain给到需要用到该数据的功能单元。如果没有链接技术，前一条指令要等到最后一个分量完成才能进行下一条指令，现在我们第一个分量完成就可以开始下一条指令的第一个分量的运算。</li>
<li>有了chaining，我们便能提高计算效率</li>
<li>convey:set of vector instructions that could potentially execute together(对于一个指令序列，如果存在结构冲突则不能放在一个convey中，数据依赖可以通过vector chaining实现)</li>
<li>chimes:sequences with read-after-write dependency hazards placed in same convey via chaining.chimes 是指在一个 convey 中，由于读后写（RAW）依赖而必须按顺序执行的指令序列。</li>
<li>chime:执行一个convey需要的时间单元</li>
</ul>
</li>
<li>optimization 2:conditional execution<ul>
<li>如果我们在向量运算中引入了conditional execution，显而易见地提高效率。否则的话存在条件分支，可能产生完全不同的执行路径，但是引入控制语句后，所有的元素都执行相同的指令，保证了向量化的进行。(控制流转化为数据流)</li>
<li>how to implement conditional execution?:引入masked register and masked vector instructions.先对每个向量判断是否满足条件，将结果保留在掩码寄存器中。实际操作时再带上掩码进行向量计算。</li>
</ul>
</li>
<li>optimization 3:sparce matrices<ul>
<li>核心技术：vector scatter&#x2F;gather.gather:从内存中将元素收集到向量寄存器中。scatter:将向量寄存器中的元素写入内存中。通过这两个操作，向量处理器就可以访问稀疏矩阵中的数据。</li>
</ul>
</li>
<li>optimization 4:Multi-lane implementation<ul>
<li>核心思想:每个时钟周期处理多个元素</li>
<li>RV64V指令集的特性：所有向量算术指令只允许向量寄存器的第N个元素与其他向量寄存器的第N个元素进行运算。根据这一个特性可以简化并行向量单元的设计：我们可以在单元构造多个multi-lane,其中每一条通道对应一条流水线。每一条通道保存所有向量寄存器的固定位置的元素，这种分配方式也就使某个通道内部的计算不需要和其他通道完成通信。</li>
<li>包含四条通道的向量单元的结构<br><img data-fancybox="gallery" data-sizes="auto" data-src="/./adsphoto/tixi20.jpg" alt="tixi20" class="lazyload"></li>
</ul>
</li>
</ul>
<h3><span id="42-simd-instruction-set-extension-for-multimedia">4.2 SIMD Instruction set extension for multimedia</span></h3><h3><span id="43-gpu">4.3 GPU</span></h3><h3><span id="44-loop-level-parallelism">4.4 Loop-Level parallelism</span></h3><ul>
<li>这一节主要研究基于循环的并行性</li>
<li>主要看循环的迭代之间是否有数据依赖(Loop-carried dependence)</li>
<li>如果循环间存在依赖，我们可以通过改写来解决</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">for</span>(i=<span class="hljs-number">0</span>;i&lt;<span class="hljs-number">100</span>;i++)<br>&#123;<br>  A[i] = A[i]+B[i];<br>  B[i+<span class="hljs-number">1</span>] = C[i]+D[i];<br>&#125;<br><span class="hljs-comment">//上面的语句存在循环依赖，因为我们的第一条语句需要用到上一个循环的第二条语句的内容</span><br><span class="hljs-comment">//为了将数据依赖删除，我们可以进行下面的改写</span><br>A[<span class="hljs-number">0</span>] = A[<span class="hljs-number">0</span>]+B[<span class="hljs-number">0</span>];<br><span class="hljs-keyword">for</span>(i=<span class="hljs-number">0</span>;i&lt;<span class="hljs-number">99</span>;i++)<br>&#123;<br>  B[i+<span class="hljs-number">1</span>] = C[i]+D[i];<br>  A[i+<span class="hljs-number">1</span>] = A[i+<span class="hljs-number">1</span>]+B[i+<span class="hljs-number">1</span>];<br>&#125;<br>B[<span class="hljs-number">100</span>] = C[<span class="hljs-number">99</span>]+D[<span class="hljs-number">99</span>];<br></code></pre></td></tr></table></figure>

<h2><span id="chapter-5tlp">chapter 5–TLP</span></h2><ul>
<li>线程级并行(更大的颗粒度并行)，在软件的层次上面下功夫。</li>
</ul>
<h3><span id="51-multiprocessor">5.1 Multiprocessor</span></h3><h4><span id="introduction">introduction</span></h4><ul>
<li>为什么使用多处理器<ul>
<li>提升性能</li>
<li>单处理器性能瓶颈</li>
<li>多处理器属于MIMD架构</li>
</ul>
</li>
</ul>
<h4><span id="the-catagory-of-multiprocessor">the catagory of multiprocessor</span></h4><ul>
<li>对称多处理器(SMP):处理器数目较少，所以处理器可以共享一个集中式存储器并且平等的访问它。（我们这种处理器在物理上是一个连续的存储器，只是逻辑上通过interconnect使得访问对应的存储器的位置）同样这种处理器可以被称为UMA(uniform memory access)一致存储器访问:所有处理器访问存储器的延迟都是一致的。</li>
<li>分布式共享处理器(DSM)也叫做NUMA:我们的处理器更多，为了支持更多的处理器，存储器必须分散在处理器之间（和UMA相比我们在物理上就已经将存储器进行分割，如果要访问需要通过interconnect来访问其他存储器，显而易见访问存储器的延迟不一致）。</li>
</ul>
<h4><span id="编程模型">编程模型</span></h4><ul>
<li>multiprogramming:无交流</li>
<li>shared address space:通过内存共享</li>
<li>Message Passing:通过消息传递</li>
<li>Data Parallellel:通过数据并行</li>
</ul>
<h4><span id="多处理器带来的问题">多处理器带来的问题</span></h4><ul>
<li>有限的程序并行性：重新写代码</li>
<li>处理器之间的通信延迟<ul>
<li>硬件解决办法:缓存共享数据（带来了缓存一致性的问题）</li>
<li>软件解决办法：同步</li>
</ul>
</li>
</ul>
<h3><span id="52-cache-coherency">5.2 Cache Coherency</span></h3><ul>
<li>在体系结构中cache coherency更多地关注一个位置上的不同处理器观测值的一致性。</li>
<li>memory consistency model：，它定义了在并发系统中，内存操作（读和写）对于不同处理器而言，它们被看到（观察到）的顺序。</li>
</ul>
<h4><span id="condition-of-coherency">condition of coherency</span></h4><ul>
<li>处理器P对位置X的读操作跟在P对X的写操作之后，并且在P的写操作和读操作之间没有其他处理器对X执行写操作</li>
<li>一个处理器对于位置X的读操作紧跟在另一个处理器对X的写操作之后，并且在两个处理器对X的访问之间没有其他处理器对X执行写操作。</li>
<li>对于同一位置的写操作是被串行化的</li>
</ul>
<h4><span id="how-to-achieve-coherency">how to achieve coherency</span></h4><ul>
<li>为多个处理器保持缓存一致性的协议成为缓存一致性协议(cache coherency protocol)<ul>
<li>监听策略(snooping)，通常运用在共享存储器</li>
<li>目录策略(directory-based)</li>
</ul>
</li>
</ul>
<h4><span id="snooping-protocol">snooping protocol</span></h4><ul>
<li>概述<ul>
<li>处理器之间可以通信，通过总线进行监听</li>
<li>如果某个处理器写入X，需要通知其他的处理器</li>
<li>其他处理器监听通知，并作出相应操作<ul>
<li>如果自己的cache也存在X，根据以下策略进行处理:<ul>
<li>write invalidate:将X的副本置为无效，做一个无效化操作，把包含X的block踢出cache。</li>
<li>write Broadcast:通过正在写入X的处理器将X的副本更新，这也就说明其他处理器能够更快的响应，因为数据还是在cache里面。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>具体实现协议–利用状态机(针对每一个cache block)<ul>
<li>每一个cache存在三种状态:<ul>
<li>invalid:无效(valid&#x3D;0)，数据无效，当前处理器不能对该缓存块进行读写操作。</li>
<li>shared:共享(dirty&#x3D;0,valid&#x3D;1)，说明数据是干净的，与主内存中的对应数据一致。</li>
<li>exclusive:独占(dirty&#x3D;1,valid&#x3D;1)，说明数据是脏的且只有当前处理器的缓存中持有该数据的有效副本。</li>
</ul>
</li>
<li>每块缓存会接受两种信号<ul>
<li>来自自己处理器的信号(cpu read,cpu write)</li>
<li>来自其他处理器的信号，也就是从bus获取的信号(bus read,bus write)，注意<strong>只有总线上的事务地址 ​​与本地Cache Line的地址完全匹配​​ 时，才会触发一致性动作。</strong></li>
</ul>
</li>
<li>当接收到自己处理器的信号的状态机:<br><img data-fancybox="gallery" data-sizes="auto" data-src="/./adsphoto/tixi21.png" alt="tixi21" class="lazyload"><br>解释：我觉得想要了解状态机的工作原理最重要的是理解三个状态的具体含义。<br>在<code>invalid</code>状态没有数据，如果要读数据就说明我们要进行同步操作转移到shared操作，写操作对于这个cache而言都会进入独占状态，并且还需要通知总线(释放write miss on bus)。<br>在<code>shared</code>状态同理，只是如果进行读操作就没有必要状态转移。<br>在<code>exclusive</code>状态，说明此时我们独占这个数据，如果发生read miss，说明这个cache line中没有我们想要的数据，我们需要替换这个赃块(write back)，并且需要通知总线(释放read miss on bus)，转移状态到shared。如果发生write miss，需要通知总线(释放write miss on bus)，然后进入exclusive状态。</li>
<li>当接收到总线的信号的状态机:<br><img data-fancybox="gallery" data-sizes="auto" data-src="/./adsphoto/tixi22.png" alt="tixi22" class="lazyload"></li>
<li>例子<br><img data-fancybox="gallery" data-sizes="auto" data-src="/./adsphoto/tixi23.png" alt="tixi23" class="lazyload"><br>解释：前面是P1处理器对于写的相关反馈，当P2处理器read miss之后，P1处理器监听到总线上的信息进行write back操作然后进入shared状态，此时P2处理器再从内存中顺利读取。再在P2处理器上执行写操作，进入exclusive状态，然后通知总线(释放write miss on bus)，P1处理器监听到总线信息以后转移状态到Invalid。最后在P2处理器执行写操作但是write miss，于是执行写回操作，内存中A1值得到更新。</li>
</ul>
</li>
</ul>
<h4><span id="mesi-protocol">MESI protocol</span></h4><ul>
<li>与传统的 Snooping Protocol不同，增加了一个exclusive状态。这会在一定程度上减少总线事务：当处理器首次读取一个cache block时如果其他处理器都没有缓存它，那么状态是Exclusive，此时写入时无需广播invalidate，直接升级为modified即可。</li>
<li>四个状态<ul>
<li>Modified(private ,!&#x3D;Memory)</li>
<li>exclusive(private ,&#x3D;&#x3D;Memory)</li>
<li>shared(shared ,&#x3D;&#x3D;Memory)</li>
<li>Invalid</li>
</ul>
</li>
<li>相应的状态机<br><img data-fancybox="gallery" data-sizes="auto" data-src="/./adsphoto/tixi24.png" alt="tixi24" class="lazyload"></li>
</ul>
<h4><span id="cache-coherency-distributed-shared-memory">cache coherency distributed shared memory</span></h4><ul>
<li>使用目录协议</li>
<li>概述<ul>
<li>directory:记录memory中每一个block的状态</li>
<li>information in directory<ul>
<li>status of every block:shared&#x2F;unncached&#x2F;exclusive<ul>
<li>我们需要明白这个状态和cache block自己维护的状态的差异，directory的状态记录每个cache block的全局共享情况。</li>
<li>shared: cache block被多个处理器共享</li>
<li>uncached: cache block没有被缓存</li>
<li>exclusive: cache block被一个处理器独占</li>
</ul>
</li>
<li>which processors have copies of the block:bit vector（sharers List）</li>
<li>这个block是否是脏的</li>
</ul>
</li>
</ul>
</li>
<li>原理<ul>
<li>没有总线也没有广播</li>
<li>三种处理器<ul>
<li>Local node where a request originates</li>
<li>Home node where the memory location of an address is located</li>
<li>Remote node has a copy of a cache block,whether exclusive or shared</li>
</ul>
</li>
<li>在目录协议中涉及的消息<br><img data-fancybox="gallery" data-sizes="auto" data-src="/./adsphoto/tixi25.png" alt="tixi25" class="lazyload"><br>解释：<br>前面三个消息是<code>缓存</code>发布的请求，与snooping协议相比，增加了 一个消息，即invalidate。<br>中间几个请求是<code>目录</code>向cache发送的请求，所以在我们下面的状态机中会出现这几个请求。<br>最后的请求是<code>remote cache</code>向目录发送的请求。</li>
<li>具体状态转化<ul>
<li>这个体系架构中cache line也同前面的snooping协议一样维护三种状态，当我们的cache接收到cpu的信息或者目录发送的信息以后会根据下面的状态机进行状态的变化。其实最主要的差异就是从shared到exclusive的write hit的情况下向home directory发送invalidate消息。<br><img data-fancybox="gallery" data-sizes="auto" data-src="/./adsphoto/tixi26.png" alt="tixi26" class="lazyload"></li>
<li>目录也要进行相应的元信息的更新。<br><img data-fancybox="gallery" data-sizes="auto" data-src="/./adsphoto/tixi27.png" alt="tixi27" class="lazyload"><ul>
<li>对于read miss：家节点接收到信息开始查看目录，可能会存在uncached(Send Rp;转化为shared状态，更新sharers&#x3D;{p})&#x2F;shared(Send Rp;sharers+&#x3D;{p})&#x2F;exclusive(先向远程node发送Fetch请,get reply back from R.N.,Send RP,-&gt;Shared,更新sharers+&#x3D;{p})三种情况</li>
<li>对于write miss:Uncached(Send Rp;S-&gt;Exclusive;sharers &#x3D; {p}),Shared(Send Invalidate;Send Rp;S-&gt;Exclusive;sharers &#x3D; {p}),Exclusive(Send Fetch&#x2F;invalidate to R.N. get reply back from R.N. Send RP to P;S-&gt;Exclusive;sharers &#x3D; {p})</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  }
};
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<span id="busuanzi_container_page_pv">
  本文总阅读量<span id="busuanzi_value_page_pv"></span>次
</span>

<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  }
};
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>


	</article>

	 
    <div class="kira-post-copyright">
        <strong>本文作者：</strong>Lane<br>
        <strong>本文链接：</strong><a href="https://lakerswillwin.github.io/2025/05/23/computersystem/" title="https:&#x2F;&#x2F;lakerswillwin.github.io&#x2F;2025&#x2F;05&#x2F;23&#x2F;computersystem&#x2F;" target="_blank" rel="noopener">https:&#x2F;&#x2F;lakerswillwin.github.io&#x2F;2025&#x2F;05&#x2F;23&#x2F;computersystem&#x2F;</a><br>
        
            <strong>版权声明：</strong>本文采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/cn/deed.zh" target="_blank">CC BY-NC-SA 3.0 CN</a> 协议进行许可
        
    </div>

  
	<div class="kira-post-nav">
		<nav class="post-nav">
			  
			<!-- 先找到与当前文字相同的目录 -->
			                  
			<!-- 在找到当前文章所在的 index -->
			                    
			<!-- 上一篇文章 -->
			<div class="old">
				<span>上一章</span>
				<a href="/2025/05/23/computerdesign/"> 数字逻辑设计对Verilog使用的记录</a>
			</div>
			       
			<!-- 下一篇文章 -->
			<div class="new">
				<span>下一章</span>
				<a href="/2025/05/23/database/"> Database system</a>
			</div>
			                                                                                          
		</nav>
	</div>
	
	<div class="kira-post-meta kira-rainbow">
		
			<a class="kirafont icon-container-fill -link" href="/categories/cs%E8%AF%BE%E7%A8%8B/">cs课程</a>
		
		
			<a class="kirafont icon-tag-fill -none-link" href="/tags/%E7%A1%AC%E4%BB%B6/" rel="tag">硬件</a>
		
	</div>
	
	<div class="kira-post-footer">
		

		
	</div>
	
</div>

				</div>
			</div>
			<div class="kira-right-column">
	<a onclick="document.querySelector('#kira-top-header').scrollIntoView({behavior: 'smooth'});" class="kira-backtotop" aria-label="回到顶部" title="回到顶部">
		<button class="mdui-fab mdui-ripple">
			<i class="kirafont icon-caret-up"></i>
		</button>
	</a>
</div>

		</div>
	</body>
</html>
